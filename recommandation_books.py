# -*- coding: utf-8 -*-
"""recommandation_books.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15w42nhqeFKpBNNW5fj9DvLimm_h-qqf3
"""

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

import seaborn as sns
import requests
import re
import string
import random

import warnings
warnings.filterwarnings("ignore")

from nltk.corpus import stopwords
from sklearn.metrics.pairwise import linear_kernel
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfVectorizer
from nltk.tokenize import RegexpTokenizer
from PIL import Image
from io import BytesIO
from sklearn.metrics.pairwise import cosine_similarity

pd.set_option('display.max_rows', 500)

!unzip /content/books.csv.zip

books=pd.read_csv("/content/data_ready.csv")
books.head()

books['categories'].nunique()

books["categories"].unique()

books.dropna(subset=['description'], inplace=True)

books = books[~books.description.str.contains('[0-9].*[0-9].*[printing]')]

# REMOVE NON ASCII CHARACTERS
def remove_non_ascii(string):
    return "".join(c for c in string if ord(c) < 128)

# MAKE DESCRIPTION TEXT LOWER CASE
def make_lower_case(text):
    return text.lower()

# REMOVE STOP WORDS
def remove_stop_words(text):
    text = text.split()
    stops = set(stopwords.words('english'))
    text = [word for word in text if not word in stops]
    text = " ".join(text)
    return text

# REMOVE PUNCTUATIONS
def remove_punctuation(text):
    tokenizer = RegexpTokenizer(r'\w+')
    text = tokenizer.tokenize(text)
    text = " ".join(text)
    return text

# REMOVE HTML CODES
def remove_html(text):
    html_pattern = re.compile('<.*?>')
    return html_pattern.sub(r'', text)

books['cleaned_description'] = books['description'].apply(remove_non_ascii)
books['cleaned_description'] = books.cleaned_description.apply(make_lower_case)

books['cleaned_description'] = books.cleaned_description.apply(remove_punctuation)
books['cleaned_description'] = books.cleaned_description.apply(remove_html)

def recommend(Titre, category):

    # MATCH THE CATEGORY WITH THE COLUMN "CATEGORIES" OF THE DATASET
    data = books.loc[books['categories'] == category]
    # RESET INDEX
    data.reset_index(level = 0, inplace = True)

    # INDEX TO A PANDAS SERIES
    indices = pd.Series(data.index, index = data['Titre'])

    # CONVERT THE BOOK TITLE INTO VECTORS AND USE BIGRAM
    tf = TfidfVectorizer(analyzer='word', ngram_range=(2, 2), min_df = 1, stop_words='english')
    tfidf_matrix = tf.fit_transform(data['Titre'])

    # CALCULATE THE SIMILARITY MEASURE
    similarity = cosine_similarity(tfidf_matrix, tfidf_matrix)

    # GET THE INDEX OF ORIGINAL TITLE
    index = indices[Titre]

    # PAIRWISE SIMILARITY SCORES
    similarity = list(enumerate(similarity[index]))
    # SORT THE BOOKS
    similarity = sorted(similarity, key=lambda x: x[1], reverse=True)

    # GET TOP 5 MOST SIMILAR BOOKS
    similarity  = similarity [1:6]

    # INDICES OF TOP 5
    book_indices = [i[0] for i in similarity]

    # TOP 5 RECOMMENDATION
    rec = data[['Titre', 'lien']].iloc[book_indices]

    # PRINT THE BOOKS TITLE
    print(rec['Titre'])

    # PRINT THE TOP 5 BOOK COVER
    for i in rec['lien']:
        response = requests.get(i)
        img = Image.open(BytesIO(response.content))
        plt.figure()
        plt.imshow(img)

response = requests.get("http://fiscow.com/product_files/img/img_pto_1.jpg")
img = Image.open(BytesIO(response.content))
plt.figure()
plt.imshow(img)
plt.show()

recommend("Rich Dad Poor Dad", "Finance")

def recommend(title, category):

    # MATCH THE CATEGORY WITH THE COLUMN "CATEGORIES" OF THE DATASET
    data = books.loc[books['categories'] == category]
    # RESET INDEX
    data.reset_index(level = 0, inplace = True)

    # INDEX TO A PANDAS SERIES
    indices = pd.Series(data.index, index = data['title'])

    # CONVERT THE BOOK TITLE INTO VECTORS AND USE BIGRAM
    tf = TfidfVectorizer(analyzer='word', ngram_range=(2, 2), min_df = 1, stop_words='english')
    tfidf_matrix = tf.fit_transform(data['cleaned_description'])

    # CALCULATE THE SIMILARITY MEASURE
    similarity = cosine_similarity(tfidf_matrix, tfidf_matrix)

    # GET THE INDEX OF ORIGINAL TITLE
    index = indices[title]

    # PAIRWISE SIMILARITY SCORES
    similarity = list(enumerate(similarity[index]))
    # SORT THE BOOKS
    similarity = sorted(similarity, key=lambda x: x[1], reverse=True)

    # GET TOP 5 MOST SIMILAR BOOKS
    similarity  = similarity [1:6]

    # INDICES OF TOP 5
    book_indices = [i[0] for i in similarity]

    # TOP 5 RECOMMENDATION
    rec = data[['title', 'thumbnail']].iloc[book_indices]

    # PRINT THE BOOKS TITLE
    print(rec['title'])

    # PRINT THE TOP 5 BOOK COVER
    for i in rec['thumbnail']:
        response = requests.get(i)
        img = Image.open(BytesIO(response.content))
        plt.figure()
        plt.imshow(img)

recommend("Taken at the Flood", "Fiction")

import requests
from PIL import Image
from io import BytesIO
import matplotlib.pyplot as plt

L = ["http://fiscow.com/product_files/img/img_pto_1.jpg"]
for i in L:
    response = requests.get(i)
    img = Image.open(BytesIO(response.content))
    plt.figure()
    plt.imshow(img)
    plt.show()

import pandas as pd

# Données
data = [
    ["Rich Dad Poor Dad", "Robert Kiyosaki", "Aucun avis", "50Dhs", "Ajouter au panier"],
    ["Why the Rich Get Richer", "Robert Kiyosaki", "Aucun avis", "55Dhs", "Ajouter au panier"],
    ["Can't Hurt Me: Master Your Mind and Defy the Odds", "David Goggins", "Aucun avis", "130Dhs", "Ajouter au panier"],
    ["Harry Potter and the Philosopher's Stone", "J. K. Rowling", "Aucun avis", "65Dhs", "Ajouter au panier"],
    ["The Richest Man in Babylon", "George Samuel Clason", "Aucun avis", "50Dhs", "Ajouter au panier"],
    ["Harry Potter and the Chamber of Secrets", "J. K. Rowling", "Aucun avis", "50Dhs", "Ajouter au panier"],
    ["The Cruel Prince", "Holly Black", "Aucun avis", "60Dhs", "Ajouter au panier"],
    ["Increase your Financial IQ: Get Smarter With Your Money", "Robert Kiyosaki", "Aucun avis", "50Dhs", "Ajouter au panier"],
    ["Eat That Frog!: Get More of the Important Things Done - Today", "Brian Tracy", "Aucun avis", "50Dhs", "Ajouter au panier"],
    ["How to Win Friends & Influence People", "Dale Carnegie", "Aucun avis", "55Dhs", "Ajouter au panier"],
    ["Forget Me Not", "Claire Allan", "Aucun avis", "60Dhs", "Ajouter au panier"],
    ["That Will Never Work: The Birth of Netflix and the Amazing Life of an Idea", "Marc Randolph", "", "70Dhs", "Ajouter au panier"],
    ["Percy Jackson and the Olympians The Lightning Thief", "Rick Riordan", "Aucun avis", "70Dhs", "Ajouter au panier"],
    ["Percy Jackson and the Olympians : The Sea of Monsters", "Rick Riordan", "Aucun avis", "75Dhs", "Ajouter au panier"],
    ["Atomic Habits: An Easy & Proven Way to Build Good Habits & Break Bad Ones", "James Clear", "Aucun avis", "74Dhs", "Ajouter au panier"],
    ["The Man Ban", "Nicola Marsh", "Aucun avis", "64Dhs", "Ajouter au panier"],
    ["People We Meet on Vacation", "Emily Henry", "Aucun avis", "57Dhs", "Ajouter au panier"],
    ["It Ends with Us", "Colleen Hoover", "Aucun avis", "70Dhs", "Ajouter au panier"],
    ["The House at the End of the Moor", "Michelle Griep", "Aucun avis", "80Dhs", "Ajouter au panier"],
    ["The Art of the Good Life : Clear Thinking for Business and a Better Life", "Unkown Author", "Aucun avis", "117Dhs", "Ajouter au panier"],
    ["The Power of Now : A Guide to Spiritual Enlightenment", "Unkown Author", "Aucun avis", "112Dhs", "Ajouter au panier"],
    ["A Return to Love: Reflections on the Principles of 'A Course in Miracles'", "Unkown Author", "Aucun avis", "124Dhs", "Ajouter au panier"],
    ["What Every BODY is Saying: An Ex-FBI Agent's Guide to Speed-Reading People", "Unkown Author", "Aucun avis", "117Dhs", "Ajouter au panier"],
    ["How to Stop Worrying and Start Living", "Dale Carnegie", "Aucun avis", "125Dhs", "Ajouter au panier"],
    ["Surrounded by Psychopaths : How to Protect Yourself from Being Manipulated and Exploited in Business and in Life", "Unkown Author", "Aucun avis", "117Dhs", "Ajouter au panier"],
    ["Mankind in the Making", "Unkown Author", "Aucun avis", "136Dhs", "Ajouter au panier"],
    ["A brief history of time", "Unkown Author", "Aucun avis", "111Dhs", "Ajouter au panier"],
    ["A Long Way Home", "Unkown Author", "Aucun avis", "119Dhs", "Ajouter au panier"],
    ["South riding", "Unkown Author", "Aucun avis", "146Dhs", "Ajouter au panier"],
    ["And thereby hangs a tale", "Unkown Author", "Aucun avis", "124Dhs", "Ajouter au panier"],
    ["Everything everything", "Unkown Author", "Aucun avis", "125Dhs", "Ajouter au panier"],
    ["Blood born", "Unkown Author", "Aucun avis", "138Dhs", "Ajouter au panier"],
    ["Chocolat : A Novel", "Unkown Author", "Aucun avis", "121Dhs", "Ajouter au panier"],
    ["Message in a bottle", "Unkown Author", "Aucun avis", "130Dhs", "Ajouter au panier"],
    ["The Seven Principles for Making Marriage Work : A Practical Guide from the Country's Foremost Relationship Expert", "Unkown Author", "Aucun avis", "122Dhs", "Ajouter au panier"],
]

categories = [
    "Finance",
    "Finance",
    "Self-Help",
    "Fantasy",
    "Finance",
    "Fantasy",
    "Fantasy",
    "Finance",
    "Self-Help",
    "Self-Help",
    "Mystery",
    "Biography",
    "Fantasy",
    "Fantasy",
    "Self-Help",
    "Romance",
    "Romance",
    "Romance",
    "Historical Fiction",
    "Self-Help",
    "Self-Help",
    "Self-Help",
    "Self-Help",
    "Self-Help",
    "Self-Help",
    "Self-Help",
    "Self-Help",
    "Self-Help",
    "Self-Help",
    "Self-Help",
    "Self-Help",
    "Self-Help",
    "Self-Help",
    "Self-Help",
    "Self-Help",

]

# Définir les noms de colonnes
columns = ["Titre", "Auteur", "Avis", "Prix", "Action"]

# Créer la DataFrame
df = pd.DataFrame(data, columns=columns)

df["categories"]= categories
# Afficher la DataFrame
df.to_csv("data.csv")

liens = ["http://fiscow.com/product_files/img/img_pto_{}.jpg".format(i) for i in range(100)]
liens

import requests

liens = ["http://fiscow.com/product_files/img/img_pto_{}.jpg".format(i) for i in range(100)]

liens_existants = []

for lien in liens:
    try:
        response = requests.get(lien)

        if response.status_code == 200:
            liens_existants.append(lien)

    except Exception as e:
        pass

print(liens_existants)
len(liens_existants)



df["lien"]=liens_existants
df.head()

import requests
from PIL import Image
from io import BytesIO
import matplotlib.pyplot as plt

for i in liens_existants:
    response = requests.get(i)
    img = Image.open(BytesIO(response.content))
    plt.figure()
    plt.imshow(img)
    plt.show()

df.to_csv("data_ready.csv")